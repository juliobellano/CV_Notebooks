{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/juliobellano/CV_Notebooks/blob/main/HuggingPics2_finetune.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ApFglcc3TASu"
      },
      "source": [
        "# HuggingPics ü§óüñºÔ∏è\n",
        "\n",
        "Fine-tune Vision Transformers for regression problem. (\"Guessthecorrelation.com\")"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XVyU3ScYZ3Hc"
      },
      "source": [
        "%%capture\n",
        "\n",
        "! pip install transformers pytorch-lightning --quiet\n",
        "! sudo apt -qq install git-lfs\n",
        "! git config --global credential.helper store"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ihFempth1zK0"
      },
      "source": [
        "import requests\n",
        "import math\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "import shutil\n",
        "import os\n",
        "from getpass import getpass\n",
        "from PIL import Image, UnidentifiedImageError\n",
        "from requests.exceptions import HTTPError\n",
        "from io import BytesIO\n",
        "from pathlib import Path\n",
        "import torch\n",
        "import pandas as pd\n",
        "import torchvision.transforms as transforms\n",
        "import pytorch_lightning as pl\n",
        "from huggingface_hub import HfApi, HfFolder, Repository, notebook_login\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torchmetrics import Accuracy\n",
        "from torchvision.datasets import ImageFolder\n",
        "from transformers import ViTFeatureExtractor, ViTForImageClassification\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "ZoWowITeoVTn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/drive/MyDrive/input.zip /content/input.zip"
      ],
      "metadata": {
        "id": "mjbsgZmqsOKI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip input.zip -d /content/input"
      ],
      "metadata": {
        "collapsed": true,
        "id": "s28ZXk7QsZFb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PKBb34N9qnNS"
      },
      "source": [
        "data_dir = Path('input/correlation_assignment/images')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v_r5KO0aMIsn"
      },
      "source": [
        "## Init Dataset and Split into Training and Validation Sets\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('input/correlation_assignment/responses.csv')\n",
        "\n",
        "image_id = df['id'].values\n",
        "labels = df['corr'].values\n",
        "print(len(image_id))"
      ],
      "metadata": {
        "id": "M8GNu0cAt3lB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_transforms = transforms.Compose([transforms.ToTensor(),\n",
        "                                 transforms.Normalize((0.5,),(0.5,))])\n",
        "class ImageDataset(Dataset):\n",
        "    def __init__(self, image_ids, labels, image_dir='input/correlation_assignment/images', transform=None):\n",
        "        self.image_ids = image_ids\n",
        "        self.labels = labels\n",
        "        self.image_dir = image_dir\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_ids)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        #get image pathhh\n",
        "        img_name = self.image_ids[idx]\n",
        "        img_path = os.path.join(self.image_dir, f\"{img_name}.png\")\n",
        "\n",
        "        #load image\n",
        "        image = Image.open(img_path).convert('1')\n",
        "\n",
        "        #apply transforms\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        #get label\n",
        "        label = self.labels[idx]\n",
        "\n",
        "        return image, label"
      ],
      "metadata": {
        "id": "lkgTFHPqyC24"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_val, y_train, y_val = train_test_split(image_id, labels, test_size=0.15, random_state=42, shuffle=True)\n",
        "print(f\"length of training dataset {len(X_train)}\")\n",
        "print(f\"length of val dataset {len(X_val)}\")\n",
        "\n",
        "train_ds = ImageDataset(X_train, y_train, transform = data_transforms)\n",
        "val_ds = ImageDataset(X_val, y_val, transform = data_transforms)"
      ],
      "metadata": {
        "id": "kv_PmdGdte6u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wbzsRQRe6iY5"
      },
      "source": [
        "plt.figure(figsize=(20,10))\n",
        "\n",
        "for i in range(6):\n",
        "    plt.subplot(2, 3, i+1)\n",
        "    plt.title(f'{y_train[i]}')\n",
        "    img = plt.imread(f'/content/input/correlation_assignment/images/{X_train[i]}.png')\n",
        "    plt.imshow(img)\n",
        "    plt.axis('off')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-1aly6Vrx2mM"
      },
      "source": [
        "## Image Classification Collator\n",
        "\n",
        "To apply our transforms to images, we'll use a custom collator class. We'll initialize it using an instance of `ViTFeatureExtractor` and pass the collator instance to `torch.utils.data.DataLoader`'s `collate_fn` kwarg."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D2n0Mf1u1ymf"
      },
      "source": [
        "class ImageClassificationCollator:\n",
        "    def __init__(self, feature_extractor):\n",
        "        self.feature_extractor = feature_extractor\n",
        "\n",
        "    def __call__(self, batch):\n",
        "        processed_images = []\n",
        "        for x in batch:\n",
        "            img = x[0]\n",
        "\n",
        "            # Convert from [-1,1] to [0,255] range\n",
        "            img = ((img + 1) * 127.5).byte()\n",
        "\n",
        "            # Convert grayscale to RGB using PIL\n",
        "            # This works better than just repeating channels\n",
        "            if img.shape[0] == 1:  # If single channel\n",
        "                # Convert tensor to PIL\n",
        "                pil_img = Image.fromarray(img[0].numpy())\n",
        "                # Convert to RGB\n",
        "                pil_img = pil_img.convert('RGB')\n",
        "                processed_images.append(pil_img)\n",
        "            else:\n",
        "                processed_images.append(img)\n",
        "\n",
        "        encodings = self.feature_extractor(processed_images, return_tensors='pt')\n",
        "        encodings['labels'] = torch.tensor([x[1] for x in batch], dtype=torch.float)\n",
        "        return encodings"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T62uFtK7LTcz"
      },
      "source": [
        "## Init Feature Extractor, Model, Data Loaders\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YovQELKD4Bu8"
      },
      "source": [
        "feature_extractor = ViTFeatureExtractor.from_pretrained('google/vit-base-patch16-224-in21k')\n",
        "model = ViTForImageClassification.from_pretrained(\n",
        "    'google/vit-base-patch16-224-in21k',\n",
        "    num_labels=1,\n",
        "    problem_type='regression'\n",
        ")\n",
        "\n",
        "model.classifier = torch.nn.Sequential(\n",
        "    torch.nn.Linear(model.classifier.in_features, 1),\n",
        "    torch.nn.Tanh()\n",
        ")\n",
        "\n",
        "\n",
        "collator = ImageClassificationCollator(feature_extractor)\n",
        "train_loader = DataLoader(train_ds, batch_size=64, collate_fn=collator, num_workers=2, shuffle=True)\n",
        "val_loader = DataLoader(val_ds, batch_size=64, collate_fn=collator, num_workers=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lEgf32rC7pQh"
      },
      "source": [
        "# Training\n",
        "\n",
        "‚ö° We'll use [PyTorch Lightning](https://pytorchlightning.ai/) to fine-tune our model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UIIRpEzW4LFo"
      },
      "source": [
        "class Classifier(pl.LightningModule):\n",
        "\n",
        "    def __init__(self, model, lr: float = 2e-5, **kwargs):\n",
        "        super().__init__()\n",
        "        self.save_hyperparameters('lr', *list(kwargs))\n",
        "        self.model = model\n",
        "        self.forward = self.model.forward\n",
        "        self.mse = torch.nn.MSELoss()\n",
        "\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        outputs = self(**batch)\n",
        "        loss = self.mse(outputs.logits.squeeze(), batch['labels'])\n",
        "        self.log(f\"train_loss\", loss)\n",
        "        return loss\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        outputs = self(**batch)\n",
        "        preds = outputs.logits.squeeze()\n",
        "        loss = self.mse(preds, batch['labels'])\n",
        "        self.log(\"val_loss\", loss)\n",
        "        return loss\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        return torch.optim.Adam(self.parameters(), lr=self.hparams.lr)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wTWYA1rf3Heg"
      },
      "source": [
        "pl.seed_everything(42)\n",
        "classifier = Classifier(model, lr=2e-5)\n",
        "trainer = pl.Trainer(accelerator='gpu', devices=1, precision=16, max_epochs=1)\n",
        "trainer.fit(classifier, train_loader, val_loader)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eJLxkmefLZT0"
      },
      "source": [
        "## Check if it Worked üòÖ"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = ('ViTtest.pt')"
      ],
      "metadata": {
        "id": "WMEwhDqXZRbL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tDfUUwH73LSq"
      },
      "source": [
        "val_batch = next(iter(val_loader))\n",
        "start_time = time.time()\n",
        "outputs = model(**val_batch)\n",
        "time = time.time() - start_time\n",
        "print(f'Inference time for 1 batch: {time}')\n",
        "print('Preds: ', outputs.logits.squeeze())\n",
        "print('Labels:', val_batch['labels'])\n",
        "model_output = outputs.logits.squeeze().detach().cpu().numpy()\n",
        "labels_actual = val_batch['labels'].cpu().numpy()\n",
        "print('model output:', model_output)\n",
        "print('Labels:', labels_actual)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.save_checkpoint(\"full_model.ckpt\")"
      ],
      "metadata": {
        "id": "EYMDdW3t5sfp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}